#
# Spring Boot Properties
#
#server.port=8181

#
# Kafka Clients Properties
#
# Kafka Bootstrap Servers
#kafka.bootstrap-servers = localhost:9092
kafka.bootstrap-servers = my-kafka-kafka-bootstrap:9092
# Kafka User Credentials
kafka.user.name     = application
kafka.user.password = ${KAFKA_USER_PASSWORD}
# To use with plain connections
kafka.security.protocol = SASL_PLAINTEXT
#kafka.security.protocol = SASL_SSL

# Producer Properties
producer.clienId = kafka-client-sb-producer-client
# No ACK
#producer.acks = 0
# Leader
#producer.acks = 1
# In-Sync
producer.acks = -1

# Consumer Properties
consumer.groupId	= kafka-client-sb-consumer
consumer.clientId	= kafka-client-sb-consumer-client
# Pooling properties
consumer.maxPoolRecords = 1000
consumer.maxPartitionFetchBytes = 1048576
# Auto commit
consumer.autoCommit = false
# latest | earliest
consumer.offsetReset = earliest
# Seconds
consumer.poolTimeout = 10

# Service Registry
#apicurio.registry.url = http://localhost:8080/apis/registry/v2
apicurio.registry.url = http://service-registry-service:8080/apis/registry/v2

#
# Spring Cloud Kubernetes Properties
#
spring.application.name=kafka-clients-sb-sample
spring.cloud.kubernetes.reload.enabled=true
#spring.cloud.kubernetes.reload.strategy=restart_context
spring.cloud.kubernetes.config.name=kafka-clients-sb-sample
spring.cloud.kubernetes.config.namespace=amq-streams-demo

#
# Spring Kafka Properties
#
spring.kafka.bootstrap-servers = ${kafka.bootstrap-servers}
spring.kafka.properties.security.protocol=${kafka.security.protocol}
spring.kafka.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${kafka.user.name}" password="${kafka.user.password}";
# Spring Kafka Producer
spring.kafka.producer.acks= ${producer.acks}
spring.kafka.producer.client-id = spring-kafka-clients-sb-producer-client
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.apicurio.registry.serde.avro.AvroKafkaSerializer
# Producer Properties
spring.kafka.producer.properties.apicurio.registry.url = ${apicurio.registry.url}
spring.kafka.producer.properties.apicurio.registry.artifact-resolver-strategy = io.apicurio.registry.serde.avro.strategy.RecordIdStrategy
# Spring Kafka Consumer
spring.kafka.listener.ack-mode = manual
spring.kafka.consumer.group-id = spring-kafka-clients-sb-sample-group
spring.kafka.consumer.auto-offset-reset = earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.key-deserializer = org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer = io.apicurio.registry.serde.avro.AvroKafkaDeserializer
# Consumer Properties
spring.kafka.consumer.properties.partition.assignment.strategy = org.apache.kafka.clients.consumer.RoundRobinAssignor
# Consumer Properties - Service Registry Integration
spring.kafka.consumer.properties.apicurio.registry.url = ${apicurio.registry.url}
# Use Specific Avro classes instead of the GenericRecord class definition
spring.kafka.consumer.properties.apicurio.registry.use-specific-avro-reader = true

#
# Swagger UI Properties
#
springdoc.version = @project.version@
springdoc.api-docs.enabled = true
springdoc.swagger-ui.path = /swagger-ui.html
springdoc.swagger-ui.displayRequestDuration = true
